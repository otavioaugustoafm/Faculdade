{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- CORREÇÃO DOS IMPORTS (Para sumir os avisos amarelos) ---\n",
    "import tensorflow as tf\n",
    "import keras # Importa o Keras separadamente\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Configurações Globais\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30 # Se estiver muito lento, mude para 10 ou 15\n",
    "LEARNING_RATE = 0.001\n",
    "base_dir = './dogs_vs_cats'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def limpar_imagens_corrompidas(folder_path):\n",
    "    print(f\"--- Verificando imagens em: {folder_path} ---\")\n",
    "    deleted_files = 0\n",
    "    \n",
    "    # Percorre todas as pastas e subpastas\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            \n",
    "            try:\n",
    "                # Tenta abrir a imagem\n",
    "                with Image.open(file_path) as img:\n",
    "                    img.verify() # Verifica a integridade do arquivo\n",
    "            except (IOError, SyntaxError, Image.UnidentifiedImageError) as e:\n",
    "                # Se der erro, deleta o arquivo\n",
    "                print(f\"Arquivo corrompido removido: {filename}\")\n",
    "                os.remove(file_path)\n",
    "                deleted_files += 1\n",
    "\n",
    "    if deleted_files == 0:\n",
    "        print(\"Nenhuma imagem corrompida encontrada.\")\n",
    "    else:\n",
    "        print(f\"Total de arquivos removidos: {deleted_files}\")\n",
    "\n",
    "# Chama a função na sua pasta base\n",
    "# Certifique-se que a variável 'base_dir' está definida como na Célula anterior\n",
    "limpar_imagens_corrompidas(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298368f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Lendo imagens de: {os.path.abspath(base_dir)}\")\n",
    "\n",
    "# --- Configuração dos Geradores com Separação Automática ---\n",
    "\n",
    "# Definimos o Data Augmentation E a divisão de validação (20%) aqui\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              # Normalização\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2         # <--- ISSO É NOVO: Separa 20% para teste automaticamente\n",
    ")\n",
    "\n",
    "# Gerador de Treino (usa 80% dos dados)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,                    # Aponta para a pasta dogs_vs_cats\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'            # <--- Pega apenas a parte de treino\n",
    ")\n",
    "\n",
    "# Gerador de Teste/Validação (usa 20% dos dados)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,               # Importante manter False para a Matriz de Confusão\n",
    "    subset='validation'          # <--- Pega apenas a parte de validação\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0994b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 5: Definição da Arquitetura do Modelo\n",
    "\n",
    "model = Sequential([\n",
    "    # Primeiro Bloco Convolucional\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=IMG_SIZE + (3,)), # (150, 150, 3)\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Segundo Bloco Convolucional\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Terceiro Bloco Convolucional\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Quarto Bloco Convolucional (Opcional, para mais complexidade)\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Camada Flatten para converter matrizes 2D em vetor 1D\n",
    "    Flatten(),\n",
    "\n",
    "    # Camada Densa (Fully Connected)\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5), # Desliga 50% dos neurônios aleatoriamente para evitar overfitting\n",
    "\n",
    "    # Camada de Saída (BINÁRIA: 1 neurônio, sigmoid)\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilação do Modelo\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy', # Obrigatório para classificação binária (0 ou 1)\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 6: Treinamento com Callbacks\n",
    "\n",
    "# Callbacks para melhorar o treinamento\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"Iniciando treinamento...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE, # Garante que passe por todas as imagens\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // BATCH_SIZE,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"Treinamento concluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e241ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 7: Plotagem dos Gráficos de Desempenho\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gráfico de Acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Acurácia de Treino')\n",
    "plt.plot(epochs_range, val_acc, label='Acurácia de Validação')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Acurácia de Treino e Validação')\n",
    "\n",
    "# Gráfico de Perda (Loss)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Perda de Treino')\n",
    "plt.plot(epochs_range, val_loss, label='Perda de Validação')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Perda de Treino e Validação')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad16c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 8: Matriz de Confusão e Relatório de Classificação\n",
    "\n",
    "# 1. Gerar previsões para o conjunto de teste/validação\n",
    "print(\"Gerando previsões...\")\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# 2. Converter probabilidades em classes (0 ou 1)\n",
    "# Se probabilidade > 0.5 é Cachorro (1), senão é Gato (0)\n",
    "y_pred = (predictions > 0.5).astype(int).ravel()\n",
    "\n",
    "# 3. Pegar as classes reais (Ground Truth)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# 4. Pegar os nomes das classes (ex: 'cat', 'dog')\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "# --- Matriz de Confusão ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# --- Relatório Completo ---\n",
    "print(\"\\nRelatório de Classificação:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
